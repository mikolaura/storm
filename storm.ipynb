{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8369ef42",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_topic = \"Impact of millon-plus token context window language models on RAG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6f12a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db1fa9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RelatedSubject(topics=['Large language models', 'Retrieval augmented generation', 'Context window', 'Natural language processing', 'Artificial intelligence', 'Machine learning', 'Deep learning', 'Transformer networks', 'Wikipedia'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "fast_llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0.0,)\n",
    "long_context_llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\",\n",
    "    temperature=0.0)\n",
    "\n",
    "gen_related_topics_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"I'm writing a Wikipedia page for a topic mentionde below. Please identify and recomend some Wikipedia pagens on clasely related topics\n",
    "    \n",
    "    Please list the as many subject and urls as you can\n",
    "    \n",
    "    Topic of interest: {topic}\"\"\"\n",
    ")\n",
    "\n",
    "class RelatedSubject(BaseModel):\n",
    "    topics: List[str] = Field(\n",
    "    description=\"Comprehensive list of related subjects as background research\",\n",
    "    )\n",
    "\n",
    "expand_chain = gen_related_topics_prompt | fast_llm.with_structured_output(RelatedSubject)\n",
    "\n",
    "related_subjects = await expand_chain.ainvoke({'topic': example_topic})\n",
    "related_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f317fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\petro_m\\AppData\\Local\\Temp\\ipykernel_6980\\3346550739.py:66: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  perspectives.dict()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'perspectives': [{'affiliation': 'Independent AI Researcher',\n",
       "   'name': 'Dr. Anya Sharma',\n",
       "   'role': 'Technical Expert',\n",
       "   'description': 'Focuses on the technical aspects of RAG, including indexing strategies, retrieval algorithms, and prompt engineering techniques optimized for long context windows.'},\n",
       "  {'affiliation': 'Enterprise Software Architect',\n",
       "   'name': 'Ben Carter',\n",
       "   'role': 'Industry Practitioner',\n",
       "   'description': 'Concerned with the practical implementation of RAG in enterprise settings, focusing on scalability, security, and integration with existing data infrastructure when using very large context windows.'},\n",
       "  {'affiliation': 'AI Ethics Institute',\n",
       "   'name': 'Professor Emily Chen',\n",
       "   'role': 'Ethical Considerations',\n",
       "   'description': 'Examines the ethical implications of using long context RAG, including potential biases in retrieved information and the impact on information access and equity.'},\n",
       "  {'affiliation': 'Linguistics Department, University X',\n",
       "   'name': 'Dr. Kenji Tanaka',\n",
       "   'role': 'Linguistic Analysis',\n",
       "   'description': 'Analyzes how extremely large context windows affect the coherence and quality of generated text, focusing on discourse structure and semantic consistency in RAG systems.'},\n",
       "  {'affiliation': 'Information Security Firm',\n",
       "   'name': 'Sarah Lee',\n",
       "   'role': 'Security Expert',\n",
       "   'description': 'Focuses on the security vulnerabilities introduced by long context RAG, including prompt injection attacks and data exfiltration risks when processing large amounts of retrieved information.'}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.retrievers import WikipediaRetriever\n",
    "from langchain_core.runnables import RunnableLambda, chain as as_runnable\n",
    "\n",
    "wikipedia_retriever = WikipediaRetriever(load_all_available_meta=True, top_k_results=1)\n",
    "\n",
    "def format_doc(doc, max_length=1000):\n",
    "    related = \"- \".join(doc.metadata['categories'])\n",
    "    return f\"### {doc.metadata['title']}\\n\\nSummary: {doc.page_content}\\nRelated: {related}\\n\\n\"[:max_length]\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([format_doc(doc) for doc in docs])\n",
    "\n",
    "\n",
    "class Editor(BaseModel):\n",
    "    affiliation: str = Field(\n",
    "        description=\"Primary affiliation of the editor\"\n",
    "    )\n",
    "    name: str = Field(\n",
    "        description=\"Name of the editor\",\n",
    "    )\n",
    "    role: str = Field(\n",
    "        description=\"Role of the editor in the context of the topic.\"\n",
    "    )\n",
    "    description: str = Field(\n",
    "        description=\"Description of the editor's focus, concers, and motives`\"\n",
    "    )\n",
    "    @property\n",
    "    def persona(self) -> str:\n",
    "        return f\"Name: {self.name}\\nRole: {self.role}\\nAffiliation: {self.affiliation}\\nDescription: {self.description}\"\n",
    "    \n",
    "class Perspectives(BaseModel):\n",
    "    perspectives: List[Editor] = Field(\n",
    "        description=\"List of editors with their perspectives on the topic\"\n",
    "    )\n",
    "\n",
    "gen_perspectives_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\n",
    "         \"\"\"You need to select a diverse(and distinc) group of Wikipedia editors who will work together to create a comprehensive article on the topic.\n",
    "         You can use other Wikipedia pages of related topics for inspiration. For each editor, add description of what they will focus on.\n",
    "         \n",
    "         Wiki page outlines of related topics for inspiration: \n",
    "         {examples}\"\"\"),\n",
    "         (\"user\",\"Topic of interest: {topic}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "gen_perspectives_chain = gen_perspectives_prompt | ChatGoogleGenerativeAI(model='gemini-2.0-flash').with_structured_output(Perspectives)\n",
    "\n",
    "@as_runnable\n",
    "async def survey_subjects(topics: str):\n",
    "    reletaed_subjects = await expand_chain.ainvoke({'topic': topics})\n",
    "    retrieved_docs = await wikipedia_retriever.abatch(reletaed_subjects.topics, return_exceptions=True)\n",
    "    all_docs = []\n",
    "    for docs in retrieved_docs:\n",
    "        if isinstance(docs, BaseException):\n",
    "            continue\n",
    "        all_docs.extend(docs)\n",
    "    formatted = format_docs(all_docs)\n",
    "    return await gen_perspectives_chain.ainvoke({\n",
    "        \"examples\": formatted,\n",
    "        \"topic\": topics\n",
    "    })\n",
    "\n",
    "perspectives = await survey_subjects.ainvoke(example_topic)\n",
    "perspectives.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adee1233",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import AnyMessage, AIMessage, BaseMessage, HumanMessage, ToolMessage\n",
    "from typing import Annotated, Sequence\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "def add_messages(left, right):\n",
    "    if not isinstance(left, list):\n",
    "        left = [left]\n",
    "    if not isinstance(right, list):\n",
    "        right = [right]\n",
    "    return left+right\n",
    "\n",
    "def update_references(references, new_references):\n",
    "    if not references:\n",
    "        references = {}\n",
    "    references.update(new_references)\n",
    "    return references\n",
    "\n",
    "def update_editor(editor, new_editor):\n",
    "    # Can only set at the outset\n",
    "    if not editor:\n",
    "        return new_editor\n",
    "    return editor\n",
    "\n",
    "\n",
    "class InterviewState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    references: Annotated[Optional[dict], update_references]\n",
    "    editor: Annotated[Optional[Editor], update_editor]\n",
    "\n",
    "\n",
    "gen_qn_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are an experienced Wikipedia writer and want to edit a specific page. \\\n",
    "Besides your identity as a Wikipedia writer, you have a specific focus when researching the topic. \\\n",
    "Now, you are chatting with an expert to get information. Ask good questions to get more useful information.\n",
    "\n",
    "When you have no more questions to ask, say \"Thank you so much for your help!\" to end the conversation.\\\n",
    "Please only ask one question at a time and don't ask what you have asked before.\\\n",
    "Your questions should be related to the topic you want to write.\n",
    "Be comprehensive and curious, gaining as much unique insight from the expert as possible.\\\n",
    "\n",
    "Stay true to your specific perspective:\n",
    "\n",
    "{persona}\"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\", optional=True),\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
